#!/usr/bin/env python3
"""
Research-question-driven Reddit insight pipeline with Anthropic analysis.

Outputs:
1) Comprehensive report markdown
2) Raw post voice + semantic labels markdown
"""

from __future__ import annotations

import argparse
import ipaddress
import json
import os
import re
import statistics
import time
from collections import Counter
from dataclasses import dataclass
from datetime import datetime, timezone
from pathlib import Path
from typing import Any
from urllib.parse import urlparse

import praw
from anthropic import Anthropic


@dataclass
class RedditPost:
    post_id: str
    title: str
    selftext: str
    subreddit: str
    score: int
    num_comments: int
    created_utc: float
    permalink: str
    url: str


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description=(
            "Decompose a research question into Reddit collection tasks, analyze posts via "
            "Anthropic, and save both a comprehensive report and raw labeled output."
        )
    )
    parser.add_argument("--question", default=None, help="Research question.")
    parser.add_argument(
        "--keyword",
        default=None,
        help="Legacy fallback. If --question is empty, this will be used as question.",
    )
    parser.add_argument(
        "--subreddit",
        default="all",
        help="Default subreddit scope for planning. Use 'all' for global search.",
    )
    parser.add_argument("--limit", type=int, default=40, help="Total posts to fetch.")
    parser.add_argument(
        "--task-count",
        type=int,
        default=4,
        help="Max Reddit collection tasks generated by LLM.",
    )
    parser.add_argument(
        "--sort",
        choices=["relevance", "hot", "top", "new", "comments"],
        default="new",
        help="Default Reddit search sort for fallback task.",
    )
    parser.add_argument(
        "--time-filter",
        choices=["all", "day", "hour", "month", "week", "year"],
        default="year",
        help="Default Reddit time filter for fallback task.",
    )
    parser.add_argument(
        "--model",
        default="claude-opus-4-5",
        help="Anthropic model name.",
    )
    parser.add_argument(
        "--output-dir",
        default="reports",
        help="Directory for generated reports.",
    )
    parser.add_argument("--reddit-client-id", default=None, help="Reddit client ID.")
    parser.add_argument(
        "--reddit-client-secret", default=None, help="Reddit client secret."
    )
    parser.add_argument("--reddit-user-agent", default=None, help="Reddit user agent.")
    parser.add_argument("--anthropic-api-key", default=None, help="Anthropic API key.")
    parser.add_argument(
        "--anthropic-base-url",
        default=None,
        help="Optional Anthropic-compatible base URL.",
    )
    args = parser.parse_args()

    question = (args.question or "").strip() or (args.keyword or "").strip()
    if not question:
        parser.error("Either --question or --keyword is required.")
    args.question = question
    return args


def required_env(key: str) -> str:
    value = os.getenv(key)
    if not value:
        raise RuntimeError(f"Missing required environment variable: {key}")
    return value


def init_reddit_client(
    client_id: str | None = None,
    client_secret: str | None = None,
    user_agent: str | None = None,
) -> praw.Reddit:
    return praw.Reddit(
        client_id=client_id or required_env("REDDIT_CLIENT_ID"),
        client_secret=client_secret or required_env("REDDIT_CLIENT_SECRET"),
        user_agent=user_agent or required_env("REDDIT_USER_AGENT"),
        check_for_async=False,
    )


def init_anthropic_client(
    api_key: str | None = None,
    base_url: str | None = None,
) -> Anthropic:
    key = api_key or required_env("ANTHROPIC_API_KEY")
    if base_url:
        _validate_base_url_runtime(base_url)
    if base_url:
        return Anthropic(api_key=key, base_url=base_url)
    return Anthropic(api_key=key)


def _validate_base_url_runtime(base_url: str) -> None:
    parsed = urlparse(base_url)
    host = (parsed.hostname or "").strip().lower()
    if not host:
        return

    is_private_host = False
    if host in {"localhost", "127.0.0.1"}:
        is_private_host = True
    else:
        try:
            ip = ipaddress.ip_address(host)
            if ip.is_private or ip.is_loopback:
                is_private_host = True
        except ValueError:
            is_private_host = False

    # Render runtime cannot reach your local/LAN gateway directly.
    if os.getenv("RENDER") and is_private_host:
        raise RuntimeError(
            "CLAUDE_BASE_URL points to a private/local address, which is unreachable from Render. "
            "Please use a public/reachable gateway endpoint, or deploy the gateway in the same network."
        )


def parse_json_response(raw_text: str) -> dict[str, Any]:
    text = raw_text.strip()
    if text.startswith("```"):
        text = text.strip("`")
        if text.startswith("json"):
            text = text[4:].strip()
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        start = text.find("{")
        end = text.rfind("}")
        if start >= 0 and end > start:
            return json.loads(text[start : end + 1])
        raise


def call_llm_json(
    anthropic_client: Anthropic,
    model: str,
    prompt: str,
    max_tokens: int = 4096,
) -> dict[str, Any]:
    last_exc: Exception | None = None
    for attempt in range(3):
        try:
            message = anthropic_client.messages.create(
                model=model,
                max_tokens=max_tokens,
                temperature=0.1,
                messages=[{"role": "user", "content": prompt}],
            )
            break
        except Exception as exc:  # noqa: BLE001
            last_exc = exc
            err = str(exc).lower()
            retryable = "timeout" in err or "timed out" in err or "connection" in err
            if attempt < 2 and retryable:
                time.sleep(1.5 * (attempt + 1))
                continue
            raise
    else:
        raise RuntimeError(f"LLM request failed after retries: {last_exc}")

    text_chunks: list[str] = []
    for block in message.content:
        if getattr(block, "type", None) == "text":
            text_chunks.append(block.text)
    if not text_chunks:
        raise RuntimeError("Anthropic returned no text response.")

    return parse_json_response("\n".join(text_chunks))


def build_task_planning_prompt(
    research_question: str,
    subreddit_scope: str,
    max_tasks: int,
    total_limit: int,
    default_sort: str,
    default_time_filter: str,
) -> str:
    schema = {
        "research_intent": "string",
        "tasks": [
            {
                "query": "string",
                "subreddit": "string",
                "sort": "new|top|relevance|comments|hot",
                "time_filter": "all|day|hour|month|week|year",
                "limit": 0,
                "rationale": "string",
            }
        ],
    }

    return (
        "You are a Reddit research planner. Convert the research question into concrete "
        "Reddit search tasks.\n"
        "Rules:\n"
        f"1) Return at most {max_tasks} tasks.\n"
        "2) Balance broad and specific queries.\n"
        "3) Include product/problem synonyms where useful.\n"
        "4) Use subreddit='all' unless niche subreddit increases relevance.\n"
        "5) Keep query short and searchable.\n"
        "6) Return valid JSON only.\n"
        f"7) Total intended fetched posts across tasks should be around {total_limit}.\n"
        "JSON schema:\n"
        f"{json.dumps(schema, ensure_ascii=True)}\n\n"
        f"Research question: {research_question}\n"
        f"Default subreddit scope: {subreddit_scope}\n"
        f"Default sort: {default_sort}\n"
        f"Default time_filter: {default_time_filter}"
    )


def normalize_task(
    task: dict[str, Any],
    default_subreddit: str,
    default_sort: str,
    default_time_filter: str,
    default_limit: int,
) -> dict[str, Any]:
    query = str(task.get("query", "")).strip()
    if not query:
        return {}

    subreddit = str(task.get("subreddit", default_subreddit)).strip() or default_subreddit
    sort = str(task.get("sort", default_sort)).lower()
    time_filter = str(task.get("time_filter", default_time_filter)).lower()

    if sort not in {"relevance", "hot", "top", "new", "comments"}:
        sort = default_sort
    if time_filter not in {"all", "day", "hour", "month", "week", "year"}:
        time_filter = default_time_filter

    raw_limit = task.get("limit", default_limit)
    try:
        limit = max(1, int(raw_limit))
    except (TypeError, ValueError):
        limit = default_limit

    rationale = str(task.get("rationale", "")).strip()

    return {
        "query": query,
        "subreddit": subreddit,
        "sort": sort,
        "time_filter": time_filter,
        "limit": limit,
        "rationale": rationale,
    }


def plan_reddit_tasks(
    anthropic_client: Anthropic,
    model: str,
    research_question: str,
    subreddit_scope: str,
    total_limit: int,
    task_count: int,
    default_sort: str,
    default_time_filter: str,
) -> dict[str, Any]:
    prompt = build_task_planning_prompt(
        research_question=research_question,
        subreddit_scope=subreddit_scope,
        max_tasks=task_count,
        total_limit=total_limit,
        default_sort=default_sort,
        default_time_filter=default_time_filter,
    )

    try:
        result = call_llm_json(
            anthropic_client=anthropic_client,
            model=model,
            prompt=prompt,
            max_tokens=2048,
        )
    except Exception:
        result = {}

    raw_tasks = result.get("tasks", []) if isinstance(result, dict) else []
    normalized: list[dict[str, Any]] = []

    per_task_default_limit = max(5, total_limit // max(1, task_count))
    for t in raw_tasks:
        if not isinstance(t, dict):
            continue
        nt = normalize_task(
            t,
            default_subreddit=subreddit_scope,
            default_sort=default_sort,
            default_time_filter=default_time_filter,
            default_limit=per_task_default_limit,
        )
        if nt:
            normalized.append(nt)

    if not normalized:
        normalized = [
            {
                "query": research_question,
                "subreddit": subreddit_scope,
                "sort": default_sort,
                "time_filter": default_time_filter,
                "limit": total_limit,
                "rationale": "Fallback single-task plan.",
            }
        ]

    return {
        "research_intent": str(result.get("research_intent", "")).strip()
        if isinstance(result, dict)
        else "",
        "tasks": normalized[: max(1, task_count)],
    }


def fetch_posts_for_tasks(
    reddit: praw.Reddit,
    tasks: list[dict[str, Any]],
    total_limit: int,
) -> list[RedditPost]:
    dedup: dict[str, RedditPost] = {}

    for task in tasks:
        if len(dedup) >= total_limit:
            break

        subreddit_name = task["subreddit"]
        query = task["query"]
        sort = task["sort"]
        time_filter = task["time_filter"]
        remaining = total_limit - len(dedup)
        limit = min(int(task["limit"]), remaining)

        subreddit = reddit.subreddit(subreddit_name)
        results = subreddit.search(
            query=query,
            sort=sort,
            time_filter=time_filter,
            limit=limit,
        )

        for p in results:
            if p.id in dedup:
                continue
            dedup[p.id] = RedditPost(
                post_id=p.id,
                title=p.title or "",
                selftext=(p.selftext or "")[:1400],
                subreddit=str(p.subreddit),
                score=int(p.score or 0),
                num_comments=int(p.num_comments or 0),
                created_utc=float(p.created_utc or 0),
                permalink=f"https://www.reddit.com{p.permalink}",
                url=p.url or "",
            )
            if len(dedup) >= total_limit:
                break

    return list(dedup.values())


def build_fallback_tasks_from_question(
    research_question: str,
    total_limit: int,
) -> list[dict[str, Any]]:
    token_candidates = re.findall(r"[A-Za-z0-9][A-Za-z0-9_-]{2,}", research_question)
    seen: set[str] = set()
    tokens: list[str] = []
    for token in token_candidates:
        t = token.lower()
        if t in seen:
            continue
        seen.add(t)
        tokens.append(token)

    queries: list[str] = []
    if research_question.strip():
        queries.append(research_question.strip())
    queries.extend(tokens[:8])

    if not queries:
        return []

    per_limit = max(3, total_limit // max(1, len(queries)))
    return [
        {
            "query": q,
            "subreddit": "all",
            "sort": "relevance",
            "time_filter": "all",
            "limit": per_limit,
            "rationale": "Fallback extraction from raw research question.",
        }
        for q in queries
    ]


def build_analysis_prompt(research_question: str, posts: list[RedditPost]) -> str:
    compact_posts = [
        {
            "id": p.post_id,
            "subreddit": p.subreddit,
            "title": p.title,
            "body": p.selftext[:900],
            "score": p.score,
            "comments": p.num_comments,
            "url": p.permalink,
            "created_utc": p.created_utc,
        }
        for p in posts
    ]

    schema = {
        "posts": [
            {
                "id": "string",
                "relevance": "high|medium|low",
                "sentiment": "positive|neutral|negative|mixed",
                "purchase_stage": "awareness|consideration|decision|postpurchase|unknown",
                "usage_scenarios": ["string"],
                "purchase_motivations": ["string"],
                "friction_factors": ["string"],
                "ad_voice_quotes": ["string"],
                "summary": "string <=40 words",
            }
        ],
        "global_insights": {
            "key_insights": ["string"],
            "top_usage_scenarios": [{"factor": "string", "count": 0}],
            "top_motivations": [{"factor": "string", "count": 0}],
            "top_frictions": [{"factor": "string", "count": 0}],
            "meta_ad_angles": [
                {
                    "angle": "string",
                    "target_scenario": "string",
                    "supporting_quotes": ["string"],
                }
            ],
        },
    }

    return (
        "You are a consumer insight analyst. Analyze Reddit posts for real-world buying "
        "context and ad messaging signals.\n"
        "Rules:\n"
        "1) Use only evidence from the provided posts.\n"
        "2) Normalize labels (concise and reusable).\n"
        "3) usage_scenarios = concrete context of use.\n"
        "4) purchase_motivations = reasons people buy.\n"
        "5) friction_factors = concerns, blockers, risks, objections.\n"
        "6) ad_voice_quotes = short original-style quotes suitable as creative inspiration.\n"
        "7) Keep each quote short (<=18 words).\n"
        "8) Return strict JSON only.\n"
        "JSON schema:\n"
        f"{json.dumps(schema, ensure_ascii=True)}\n\n"
        f"Research question: {research_question}\n"
        f"Posts JSON: {json.dumps(compact_posts, ensure_ascii=True)}"
    )


def analyze_posts(
    anthropic_client: Anthropic,
    model: str,
    research_question: str,
    posts: list[RedditPost],
) -> dict[str, Any]:
    prompt = build_analysis_prompt(research_question=research_question, posts=posts)
    return call_llm_json(
        anthropic_client=anthropic_client,
        model=model,
        prompt=prompt,
        max_tokens=4096,
    )


def aggregate_quant_stats(posts: list[RedditPost], analysis: dict[str, Any]) -> dict[str, Any]:
    analyzed_posts = analysis.get("posts", [])

    scenario_counter: Counter[str] = Counter()
    motivation_counter: Counter[str] = Counter()
    friction_counter: Counter[str] = Counter()
    stage_counter: Counter[str] = Counter()
    sentiment_counter: Counter[str] = Counter()
    relevance_counter: Counter[str] = Counter()

    score_counts = [p.score for p in posts]
    comment_counts = [p.num_comments for p in posts]

    for ap in analyzed_posts:
        stage_counter[str(ap.get("purchase_stage", "unknown")).lower()] += 1
        sentiment_counter[str(ap.get("sentiment", "unknown")).lower()] += 1
        relevance_counter[str(ap.get("relevance", "unknown")).lower()] += 1

        for factor in ap.get("usage_scenarios", []) or []:
            if isinstance(factor, str) and factor.strip():
                scenario_counter[factor.strip().lower()] += 1

        for factor in ap.get("purchase_motivations", []) or []:
            if isinstance(factor, str) and factor.strip():
                motivation_counter[factor.strip().lower()] += 1

        for factor in ap.get("friction_factors", []) or []:
            if isinstance(factor, str) and factor.strip():
                friction_counter[factor.strip().lower()] += 1

    return {
        "total_posts_fetched": len(posts),
        "total_posts_analyzed": len(analyzed_posts),
        "avg_score": round(statistics.mean(score_counts), 2) if score_counts else 0,
        "median_score": statistics.median(score_counts) if score_counts else 0,
        "avg_comments": round(statistics.mean(comment_counts), 2) if comment_counts else 0,
        "median_comments": statistics.median(comment_counts) if comment_counts else 0,
        "relevance_distribution": dict(relevance_counter),
        "stage_distribution": dict(stage_counter),
        "sentiment_distribution": dict(sentiment_counter),
        "top_usage_scenarios": scenario_counter.most_common(10),
        "top_motivations": motivation_counter.most_common(10),
        "top_frictions": friction_counter.most_common(10),
    }


def to_dt_str(created_utc: float) -> str:
    return datetime.fromtimestamp(created_utc, tz=timezone.utc).strftime("%Y-%m-%d")


def render_comprehensive_report(
    research_question: str,
    plan: dict[str, Any],
    posts: list[RedditPost],
    analysis: dict[str, Any],
    stats: dict[str, Any],
) -> str:
    analyzed_map = {str(item.get("id", "")): item for item in analysis.get("posts", [])}
    global_insights = analysis.get("global_insights", {})

    lines: list[str] = []
    lines.append("# Reddit Research Insight Report")
    lines.append("")
    lines.append("## Research Question")
    lines.append(research_question)
    lines.append("")

    lines.append("## Run Metadata")
    lines.append(f"- Generated at (UTC): {datetime.now(timezone.utc).isoformat()}")
    lines.append(f"- Posts fetched: {stats['total_posts_fetched']}")
    lines.append(f"- Posts analyzed: {stats['total_posts_analyzed']}")
    if plan.get("research_intent"):
        lines.append(f"- Interpreted research intent: {plan['research_intent']}")
    lines.append("")

    lines.append("## Reddit Collection Plan (LLM Decomposed)")
    for idx, task in enumerate(plan.get("tasks", []), start=1):
        lines.append(
            f"{idx}. query=`{task.get('query', '')}`, subreddit=`{task.get('subreddit', '')}`, "
            f"sort=`{task.get('sort', '')}`, time_filter=`{task.get('time_filter', '')}`, "
            f"limit={task.get('limit', 0)}"
        )
        rationale = str(task.get("rationale", "")).strip()
        if rationale:
            lines.append(f"   rationale: {rationale}")
    lines.append("")

    lines.append("## Quantitative Summary")
    lines.append(f"- Avg score: {stats['avg_score']}")
    lines.append(f"- Median score: {stats['median_score']}")
    lines.append(f"- Avg comments: {stats['avg_comments']}")
    lines.append(f"- Median comments: {stats['median_comments']}")
    lines.append("")

    lines.append("### Relevance Distribution")
    for k, v in stats.get("relevance_distribution", {}).items():
        lines.append(f"- {k}: {v}")
    lines.append("")

    lines.append("### Purchase Stage Distribution")
    for k, v in stats.get("stage_distribution", {}).items():
        lines.append(f"- {k}: {v}")
    lines.append("")

    lines.append("### Sentiment Distribution")
    for k, v in stats.get("sentiment_distribution", {}).items():
        lines.append(f"- {k}: {v}")
    lines.append("")

    lines.append("### Top Usage Scenarios")
    for factor, count in stats.get("top_usage_scenarios", []):
        lines.append(f"- {factor}: {count}")
    lines.append("")

    lines.append("### Top Purchase Motivations")
    for factor, count in stats.get("top_motivations", []):
        lines.append(f"- {factor}: {count}")
    lines.append("")

    lines.append("### Top Friction / Concerns")
    for factor, count in stats.get("top_frictions", []):
        lines.append(f"- {factor}: {count}")
    lines.append("")

    lines.append("## Key Insights")
    for insight in global_insights.get("key_insights", []):
        lines.append(f"- {insight}")
    lines.append("")

    lines.append("## Meta Ad Angles (From Reddit Voice)")
    for angle_item in global_insights.get("meta_ad_angles", []):
        angle = angle_item.get("angle", "")
        target = angle_item.get("target_scenario", "")
        lines.append(f"- Angle: {angle}")
        lines.append(f"  Target scenario: {target}")
        for quote in angle_item.get("supporting_quotes", []) or []:
            lines.append(f"  Quote: \"{quote}\"")
    lines.append("")

    lines.append("## Post-Level Snapshot")
    for p in posts:
        ap = analyzed_map.get(p.post_id, {})
        lines.append(f"### {p.title}")
        lines.append(f"- Post ID: `{p.post_id}`")
        lines.append(f"- Date (UTC): {to_dt_str(p.created_utc)}")
        lines.append(f"- Subreddit: r/{p.subreddit}")
        lines.append(f"- Score: {p.score}, Comments: {p.num_comments}")
        lines.append(f"- Link: {p.permalink}")
        lines.append(f"- Relevance: {ap.get('relevance', 'n/a')}")
        lines.append(f"- Stage: {ap.get('purchase_stage', 'n/a')}")
        lines.append(f"- Summary: {ap.get('summary', 'n/a')}")
        lines.append("")

    return "\n".join(lines).strip() + "\n"


def render_raw_labeled_markdown(
    research_question: str,
    posts: list[RedditPost],
    analysis: dict[str, Any],
) -> str:
    analyzed_map = {str(item.get("id", "")): item for item in analysis.get("posts", [])}

    lines: list[str] = []
    lines.append("# Reddit Raw Voice + Semantic Labels")
    lines.append("")
    lines.append("## Research Question")
    lines.append(research_question)
    lines.append("")

    for p in posts:
        ap = analyzed_map.get(p.post_id, {})
        lines.append(f"## {p.title}")
        lines.append(f"- Post ID: `{p.post_id}`")
        lines.append(f"- Subreddit: r/{p.subreddit}")
        lines.append(f"- Date (UTC): {to_dt_str(p.created_utc)}")
        lines.append(f"- Score: {p.score}, Comments: {p.num_comments}")
        lines.append(f"- Link: {p.permalink}")
        lines.append("")

        lines.append("### Original Voice")
        lines.append(f"- Title: {p.title}")
        body = p.selftext.strip() or "(No self text; title/url-only post)"
        lines.append(f"- Body: {body}")
        lines.append("")

        lines.append("### Semantic Labels")
        lines.append(f"- Relevance: {ap.get('relevance', 'n/a')}")
        lines.append(f"- Sentiment: {ap.get('sentiment', 'n/a')}")
        lines.append(f"- Purchase stage: {ap.get('purchase_stage', 'n/a')}")
        usage = ap.get("usage_scenarios", [])
        motivations = ap.get("purchase_motivations", [])
        frictions = ap.get("friction_factors", [])
        quotes = ap.get("ad_voice_quotes", [])
        lines.append(f"- Usage scenarios: {', '.join(usage) if usage else 'n/a'}")
        lines.append(f"- Purchase motivations: {', '.join(motivations) if motivations else 'n/a'}")
        lines.append(f"- Frictions/concerns: {', '.join(frictions) if frictions else 'n/a'}")
        lines.append(f"- Ad voice quotes: {', '.join([f'\"{q}\"' for q in quotes]) if quotes else 'n/a'}")
        lines.append(f"- Summary: {ap.get('summary', 'n/a')}")
        lines.append("")

    return "\n".join(lines).strip() + "\n"


def slugify(text: str) -> str:
    cleaned = "".join(c for c in text.lower().strip() if c.isalnum() or c in ("-", "_", " "))
    return "_".join(cleaned.split())[:80] or "query"


def save_outputs(
    comprehensive_markdown: str,
    raw_labeled_markdown: str,
    output_dir: str,
    research_question: str,
) -> dict[str, Path]:
    out_dir = Path(output_dir)
    out_dir.mkdir(parents=True, exist_ok=True)

    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    slug = slugify(research_question)

    report_path = out_dir / f"reddit_insight_report_{slug}_{ts}.md"
    raw_path = out_dir / f"reddit_raw_labeled_{slug}_{ts}.md"

    report_path.write_text(comprehensive_markdown, encoding="utf-8")
    raw_path.write_text(raw_labeled_markdown, encoding="utf-8")

    return {
        "report_path": report_path,
        "raw_labeled_path": raw_path,
    }


def run_pipeline(
    *,
    research_question: str,
    subreddit: str = "all",
    limit: int = 40,
    task_count: int = 4,
    sort: str = "new",
    time_filter: str = "year",
    model: str = "claude-opus-4-5",
    output_dir: str = "reports",
    reddit_client_id: str | None = None,
    reddit_client_secret: str | None = None,
    reddit_user_agent: str | None = None,
    anthropic_api_key: str | None = None,
    anthropic_base_url: str | None = None,
) -> dict[str, Path]:
    reddit = init_reddit_client(
        client_id=reddit_client_id,
        client_secret=reddit_client_secret,
        user_agent=reddit_user_agent,
    )
    anthropic_client = init_anthropic_client(
        api_key=anthropic_api_key,
        base_url=anthropic_base_url,
    )

    plan = plan_reddit_tasks(
        anthropic_client=anthropic_client,
        model=model,
        research_question=research_question,
        subreddit_scope=subreddit,
        total_limit=limit,
        task_count=task_count,
        default_sort=sort,
        default_time_filter=time_filter,
    )

    posts = fetch_posts_for_tasks(
        reddit=reddit,
        tasks=plan.get("tasks", []),
        total_limit=limit,
    )
    if not posts:
        fallback_tasks = build_fallback_tasks_from_question(
            research_question=research_question,
            total_limit=limit,
        )
        posts = fetch_posts_for_tasks(
            reddit=reddit,
            tasks=fallback_tasks,
            total_limit=limit,
        )
        if fallback_tasks:
            plan["tasks"] = (plan.get("tasks", []) or []) + fallback_tasks
        if not posts:
            raise RuntimeError(
                "No posts fetched from planned and fallback tasks. "
                "Try broader question, fix brand spelling, or use subreddit=all/time_filter=all."
            )

    analysis = analyze_posts(
        anthropic_client=anthropic_client,
        model=model,
        research_question=research_question,
        posts=posts,
    )

    stats = aggregate_quant_stats(posts, analysis)

    report_md = render_comprehensive_report(
        research_question=research_question,
        plan=plan,
        posts=posts,
        analysis=analysis,
        stats=stats,
    )
    raw_md = render_raw_labeled_markdown(
        research_question=research_question,
        posts=posts,
        analysis=analysis,
    )

    return save_outputs(
        comprehensive_markdown=report_md,
        raw_labeled_markdown=raw_md,
        output_dir=output_dir,
        research_question=research_question,
    )


def main() -> None:
    args = parse_args()
    outputs = run_pipeline(
        research_question=args.question,
        subreddit=args.subreddit,
        limit=args.limit,
        task_count=args.task_count,
        sort=args.sort,
        time_filter=args.time_filter,
        model=args.model,
        output_dir=args.output_dir,
        reddit_client_id=args.reddit_client_id,
        reddit_client_secret=args.reddit_client_secret,
        reddit_user_agent=args.reddit_user_agent,
        anthropic_api_key=args.anthropic_api_key,
        anthropic_base_url=args.anthropic_base_url,
    )

    print(f"Comprehensive report saved: {outputs['report_path']}")
    print(f"Raw labeled report saved: {outputs['raw_labeled_path']}")


if __name__ == "__main__":
    main()
